{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc87aa0b",
   "metadata": {},
   "source": [
    "## 예제2-1) 사람의 손글씨 데이터인 MNIST를 이용해 MLP 설계하기\n",
    "  \n",
    "  \n",
    "### 1. 모듈 임포트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a16774f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn                           # (1)\n",
    "import torch.nn.functional as F                 # (2)\n",
    "from torchvision import transforms, datasets    # (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aaf426",
   "metadata": {},
   "source": [
    "(1) PyTorch 모듈 중 딥러닝, 즉 인공 신경망 모델을 설계할 때 필요한 함수를 모아 놓은 모듈  \n",
    "(2) torch.nn 모듈 중에서도 자주 이용되는 함수를 \"F\"라고 지정  \n",
    "(3) 컴퓨터 비전 연구 분야에서 자주 이요하는 'torchvision' 모듈 내 'transforms', 'datasets'함수 임포트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c672491a",
   "metadata": {},
   "source": [
    "### 2. 딥러닝 모델을 설계할 때 활용하는 장비 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfa835c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version :  1.9.0  Device :  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nyongja/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() :\n",
    "    DEVICE = torch.device('cuda')\n",
    "else :\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version : ', torch.__version__, ' Device : ', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ff346",
   "metadata": {},
   "source": [
    "파이토치 프레임워크를 이용해 딥러닝 설계 / 구성 시 파라미터 값을 업데이트 할 때 이용할 장비를 선택할 수 있음.  \n",
    "GPU 사용 시 계산 속도가 빨라 파라미터 값을 빠르게 업데이트 할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4107b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32    # (1)\n",
    "EPOCHS = 10        # (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ec503",
   "metadata": {},
   "source": [
    "파이썬 코드 내 하이퍼파라미터는 보통 영어 대문자로 표기.  \n",
    "\n",
    "(1) BATCH_SIZE : MLP 모델을 학습할 때 필요한 데이터 개수의 단위.  Mini-Batch 1개 단위에 대해 데이터가 32개로 구성돼 있는 것을 의미함. 1개의 mini-batch를 이용해 학습하는 횟수를 'iteration', 전체 데이터를 이용해 학습을 진행한 횟수를 'epoch'이라고 함. 예를 들어, 전체 데이터가 1만개이고, 1000개 데이터를 이용해 1개의 mini-batch를 구성한다면 1epoch 당 10회의 iteration이 발생함.  \n",
    "(2) EPOCHS : mini-batch 1개 단위로 back propagation을 이용해 MLP의 가중값을 업데이트. epoch은 존재하고 있는 mini-batch를 전부 이용하는 횟수를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9a97c",
   "metadata": {},
   "source": [
    "### 3. MNIST 데이터 다운로드(Train set, Test set 분리하기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1796c891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nyongja/anaconda3/envs/pytorch_study/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448224956/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\",                 #(1)\n",
    "                              train = True,\n",
    "                              download = True,\n",
    "                              transform = transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root = \"../data/MNIST\",                  #(2)\n",
    "                              train = False,\n",
    "                              transform = transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,    #(3)\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,     #(4)\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de37675",
   "metadata": {},
   "source": [
    "흔히 데이터를 외부에서 파이썬으로 불러와 이용하며 pandas module로 처리함.  \n",
    "이외에도 'PyTorch'에서 연구용으로 자주 이용하는 데이터를 쉽게 불러올 수 있도록 구현되어 있음.  \n",
    "\n",
    "MLP 모델 학습하기 위해 이용하는 학습용 데이터셋과 학습이 진행된 후 성능 검증을 위한 검증용 데이터셋을 따로 분리해 설정.  \n",
    "(1), (2) MNIST 데이터셋을 다운로드.  \n",
    "- root : 데이터가 저장될 장소  \n",
    "- train : 대상 데이터가 학습용인지 검증용인지 설정  \n",
    "- download : 데이터를 다운로드해서 사용할 것인지\n",
    "- transform : 데이터를 다운로드할 때, 이미지 데이터에 대한 기본적인 전처리를 동시에 진행. 'ToTensor()'메서드를 이용해 'tensor'형태로 데이터를 변경해주며, 한 픽셀은 0\\~255 범위 스칼라 값으로 구성돼 있는데 이를 0\\~1 범위로 정규화 과정을 진행해줌. MLP 모델이 포함된 인공 신경망 모델은 input 데이터 값의 크기가 커질수록 불안정하거나 과적합되는 방향으로 학습이 진행될 우려가 있으므로 정규화 과정을 이용해 input으로 이용하는 것을 권장함. \n",
    "\n",
    "\n",
    "(3), (4) 다운로드한 데이터셋을 mini-batch 단위로 분리해 지정함. 이미지 데이터 1개는 각각을 이용해 MLP 모델을 학습시키는 것이 아니라 이미지 데이터를 batch size만큼, 즉 32개만큼 묶어 1개의 mini-batch를 구성하는 것을 'DataLoader'함수를 이용해 진행할 수 있음.    \n",
    "- dataset : Mini-Batch 단위로 할당하고자 하는 데이터셋을 지정. 'train_dataset'을 이용해 학습을 진행하는 'DataLoader'를 'train_loader', 'test_dataset'을 'test_loader'로 설정\n",
    "- batch_size : Mini-batch 1개 단위를 구성하는 데이터의 개수 지정. \n",
    "- shuffle : 데이터의 순서를 섞고자 할때. MLP 모델이 학습 진행할 때 Label 정보의 순서를 암기해 학습을 진행할 수 있음. 즉, 특정 Label에 매칭된 이미지 데이터의 특징을 보고 학습하는 것이 아니라 틀정 이미지 데이터에 매칭된 Label 값만을 집중적으로 학습하는, 즉 잘못된 방향으로 학습하는 것을 방지하기 위해 데이터 순서를 섞는 과정."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a27dc",
   "metadata": {},
   "source": [
    "### 4. 데이터 확인하기(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa6027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([32, 1, 28, 28]) type :  torch.FloatTensor\n",
      "y_train :  torch.Size([32]) type :  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader :\n",
    "    print('X_train : ', X_train.size(), 'type : ', X_train.type())\n",
    "    print('y_train : ', y_train.size(), 'type : ', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185bfe3",
   "metadata": {},
   "source": [
    "다운로드한 후 mini-batch 단위로 할당한 데이터의 개수와 형태를 확인.  \n",
    "- X_train : 32개의 이미지 데이터가 1개의 Mini-Batch를 구성하고 있고 가로 28개, 세로 28개의 픽셀로 구성돼 있으며 채널이 1이므로 그레이스케일로 이뤄진, 즉 흑백 이미지 데이터라는 것을 확인할 수 있음. \n",
    "- y_train : 32개의 이미지 데이터 각각에 label 값이 1개 존재하므로 32개의 값을 갖고 있다는 것을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a8b93",
   "metadata": {},
   "source": [
    "### 5. 데이터 확인하기(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20c503b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "for i in range(10) :\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap = \"gray_r\")\n",
    "    plt.title('Class : ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0de531",
   "metadata": {},
   "source": [
    "### 6. MLP(Multi Layer Perceptron) 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a003d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module) :                        #(1)\n",
    "    def __init__(self) :                      #(2)\n",
    "        super(Net, self).__init__()           #(3)\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)    #(4)\n",
    "        self.fc2 = nn.Linear(512, 256)        #(5)\n",
    "        self.fc3 = nn.Linear(256, 10)         #(6)\n",
    "        \n",
    "    def forward(self, x) :                    #(7)\n",
    "        x = x.view(-1, 28 * 28)               #(8)\n",
    "        x = self.fc1(x)                       #(9)\n",
    "        x = F.sigmoid(x)                      #(10)\n",
    "        x = self.fc2(x)                       #(11)\n",
    "        x = F.sigmoid(x)                      #(12)\n",
    "        x = self.fc3(x)                       #(13)\n",
    "        x = F.log_softmax(x, dim = 1)         #(14)\n",
    "        return x                              #(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9951b1",
   "metadata": {},
   "source": [
    "torch 모듈을 이용해 본격적으로 MLP를 설계하는 단계.  \n",
    "(1) PyTorch Module 내에 딥러닝 모델 관련 기본 함수를 포함하고 있는 nn.Module 클래스를 상속받는 Net 클래스를 정의. nn.Module 클래스를 상속받았을 때 nn.Module 클래스가 이용할 수 있는 함수를 그대로 이용할 수 있기 때문에 새로운 딥러닝 모델을 설계할 때 자주 이용.  \n",
    "(2) Net 클래스의 인스턴스를 생성했을 때 지니게 되는 성질을 정의해주는 메서드.  \n",
    "(3) nn.Module 내에 있는 메서드를 상속받아 이용.  \n",
    "(4) 첫 번째 Fully Connected Layer 정의. MNIST 데이터를 Input으로 사용하기 위해 28*28*1(가로 픽셀 수 * 세로 픽셀 수 * 채널 수) 크기의 노드 수를 설정한 후 두 번째 Fully Connected Layer의 노드 수를 512개로 설정할 것이므로 output의 노드 수는 512개로 설정.  \n",
    "(5) 두 번째 Fully Connected Layer 정의. \n",
    "(6) 세 번째 Fully Connected Layer 정의. 0부터 9까지의 총 10가지 클래스를 표현하기 위한 Label 값은 원-핫 인코딩으로 표현. MLP 모델의 Output 값과 Loss를 계산하려면 이에 맞는 크기의 벡터를 계산해야 함. 따라서 Output 노드 수를 10개로 정의.  \n",
    "(7) Net 클래스를 이용해 설계한 MLP 모델의 Forward Propagation 정의. 즉, 설계한 MLP 모델에 데이터를 입력했을 때 Output을 계산하기까지의 과정을 나열한 것을 의미.  \n",
    "(8) MLP 모델은 1차원의 벡터 값을 입력으로 받을 수 있음. 하지만 MNIST 이미지 데이터는 크기가 28\\*28인 2차원 데이터. 따라서 2차원 데이터를 1차원 데이터로 변환하려면 View 메서드를 이용해 784 크기의 1차원 데이터로 변환해 진행해야 함. 이를 '2차원의 데이터를 1차원으로 펼친다'라고 표현하며 'Flatten한다'라고 표현함.  \n",
    "(9) 첫 번째 Fully Connected Layer에 1차원으로 펼친 이미지 데이터를 통과시킴\n",
    "(10) PyTorch Module 중 인공 신경망 설계에 유용한 함수를 모아 놓은 torch.nn.functional 내에 정의된 비선형 함수는 sigmoid()를 이용해 두 번째 Fully Connected Layer의 input으로 계산함.  \n",
    "(11) 첫 번째 Fully Connected Layer에 sigmoid()함수를 이용해 계산된 결괏값을 통과시킴.  \n",
    "(12) PyTorch Module 중 인공 신경망 설계에 유용한 함수를 모아 놓은 torch.nn.functional 내에 정의된 비선형 함수는 sigmoid()를 이용해 세 번째 Fully Connected Layer의 input으로 계산함.  \n",
    "(13) 두 번째 Fully Connected Layer에 sigmoid()함수를 이용해 계산된 결괏값을 통과시킴.  \n",
    "(14) PyTorch Module 중 인공 신경망 설계에 유용한 함수를 모아 놓은 torch.nn.functional 내의 log.softmax()를 이용해 최종 Output을 계산. 0부터 9까지, 총 10가지 경우의 수 중 하나로 분류하는 일을 수행하기 때문에 softmax를 이용해 확률 값 게산. 일반적인 softmax 대신 log_softmax()를 이용하는 이유는 MLP 모델이 Back Propagation 알고리즘을 이용해 학습 진행 시 Loss 값에 대한 Gradient 값을 좀 더 원활하게 계산할 수 있으므로. (log 함수 그래프의 기울기가 부드럽게 변화하는 것을 상상해보면 됨!)  \n",
    "(15) 최종 계산된 값 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a7c38",
   "metadata": {},
   "source": [
    "### 7. Optimizer, Objective Function 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fff5b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(DEVICE)                                                      # (1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)    # (2)\n",
    "criterion = nn.CrossEntropyLoss()                                             # (3)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48565636",
   "metadata": {},
   "source": [
    "(1) MLP 모델을 기존에 선정한 'DEVICE'에 할당 -> 'DEVICE' 장비를 이용해 MLP 모델을 완성하기 위해서!  \n",
    "(2) Back Propagation을 이용해 파라미터를 업데이트할 때 이용하는 Optimizer를 정의. 이 예제에서는 SGD 알고리즘을 이용하며 파라미터를 업데이트할 때 반영될 Learning Rate를 '0.01', Optimizer의 관성을 나타내는 momentum을 '0.5'로 설정.  \n",
    "(3) MLP 모델의 output 값과 계산될 Label 값은 Class를 표현하는 원-핫 인코딩 값. MLP 모델의 output 값과 원-핫 인코딩 값과의 Loss는 CrossEntropy를 이용해 계산하기 위해 criterion은 'nn.CrossEntropyLoss()'로 설정."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233fd03",
   "metadata": {},
   "source": [
    "### 8. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ca8c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_interval) :\n",
    "    model.train()                                                                              # (1)\n",
    "    for batch_idx, (image, label) in enumerate(train_loader) :                                 # (2)\n",
    "        image = image.to(DEVICE)                                                               # (3)\n",
    "        label = label.to(DEVICE)                                                               # (4)\n",
    "        optimizer.zero_grad()                                                                  # (5)\n",
    "        output = model(image)                                                                  # (6)\n",
    "        loss = criterion(output, label)                                                        # (7)\n",
    "        loss.backward()                                                                        # (8)\n",
    "        optimizer.step()                                                                       # (9)\n",
    "        \n",
    "        if batch_idx % log_interval == 0 :\n",
    "            print(\"Train Eppoch : {} [{}/{}({:.0f}%)]\\tTrain Loss : {:.6f}\".format(\n",
    "                Epoch, batch_idx * len(image), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b837331",
   "metadata": {},
   "source": [
    "기존에 정의한 이미지 데이터와 레이블 데이터를 이용해 MLP 모델을 학습하는 train 함수 정의하기  \n",
    "(1) 기존에 정의한 MLP 모델을 학습 상태로 지정.  \n",
    "(2) 기존에 정의한 'train_loader'에는 학습에 이용되는 이미지 데이터와 레이블 데이터가 Mini-batch 단위로 묶여 저장돼 있음. 해당 'train_loader'내에 Mini-Batch 단위로 저장된 데이터를 순서대로 이용해 MLP 모형 학습.  \n",
    "(3) Mini-Batch 내에 있는 이미지 데이터를 이용해 MLP 모델을 학습시키기 위해 기존에 정의한 장비에 할당.  \n",
    "(4) Mini-Batch 내에 있는 이미지 데이터와 매칭된 레이블 데이터도 기존에 정의한 장비에 할당.  \n",
    "(5) 기존에 정의한 장비에 이미지 데이터와 레이블 데이터를 할당한 경우, 과거에 이용한 Mini-Batch 내에 있는 이미지 데이터와 레이블 데이터를 바탕으로 계산된 Loss의 Gradient 값이 optimizer에 할당돼 있으므로 optimizer의 Gradient를 초기화함.  \n",
    "(6) 장비에 할당한 이미지 데이터를 MLP 모델의 Input으로 이용해 Output을 계산.  \n",
    "(7) 계산된 Output과 장비에 할당된 레이블 데이터를 기존에 정의한 CrossEntropy를 이용해 Loss 값 계산.  \n",
    "(8) Loss 값을 계산한 결과를 바탕으로 Back Propagation을 통해 계산된 Gradient 값을 각 파라미터에 할당.  \n",
    "(9) 각 파라미터에 할당된 Gradient값을 이용해 파라미터 값을 업데이트."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0479a",
   "metadata": {},
   "source": [
    "### 9. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e3a6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader) :\n",
    "    model.eval()                                                                     # (1)\n",
    "    test_loss = 0                                                                    # (2)\n",
    "    correct = 0                                                                      # (3)\n",
    "    \n",
    "    with torch.no_grad() :                                                           # (4)\n",
    "        for image, label in test_loader :                                            # (5)\n",
    "            image = image.to(DEVICE)                                                 # (6)\n",
    "            label = label.to(DEVICE)                                                 # (7)\n",
    "            output = model(image)                                                    # (8)\n",
    "            test_loss += criterion(output, label).item()                             # (9)\n",
    "            prediction = output.max(1, keepdim = True)[1]                            # (10)\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()         # (11)\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)                                            # (12)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)                        # (13)\n",
    "    return test_loss, test_accuracy                                                  # (14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd9a2a6",
   "metadata": {},
   "source": [
    "(1) 학습 과정 또는 학습이 완료된 MLP 모델을 학습 상태가 아닌, 평가 상태로 지정.  \n",
    "(2) 기존에 정의한 'test_loader' 내의 데이터를 이용해 Loss 값을 계산하기 위해 'test_loss'를 0으로 임시 설정.  \n",
    "(3) 학습 과정 또는 학습이 완료된 MLP 모델이 올바른 Class로 분류한 경우를 세기 위해 correct = 0으로 임시 설정.  \n",
    "(4) MLP 모델을 평가하는 단계에서는 Gradient를 통해 파라미터 값이 업데이트되는 현상을 방지하기 위해 'torch.no.grad()' 메서드를 이용해 Gradient의 흐름을 억제.  \n",
    "(5) 기존에 정의한 'test_loader'내의 데이터로 mini-batch 단위로 저장돼 있음. Mini-Batch 내에 있는 이미지 데이터와 레이블 데이터에 반복문을 이용해 차례대로 접근.  \n",
    "(6) Mini-Batch 내에 있는 이미지 데이터를 이용해 MLP 모델을 검증하기 위해 기존에 정의한 장비에 할당.  \n",
    "(7) Mini-Batch 내에 있는 이미지 데이터와 매칭된 레이블 데이터도 기존에 정의한 장비에 할당.  \n",
    "(8) 장비에 할당한 이미지 데이터를 MLP 모델의 Input으로 Output을 계산.  \n",
    "(9) 계산된 Output과 장비에 할당된 레이블 데이터를 기존에 정의한 CrossEntropy를 이용해 Loss 값을 계산한 결괏값을 'test_loss'에 더해 업데이트.  \n",
    "(10) MLP 모델의 Output 값은 크기가 10인 벡터 값. 계산된 벡터 값 내 가장 큰 값인 위치에 대해 해당 위치에 대응하는 클래스로 예측했다고 판단.  \n",
    "(11) MLP 모델이 최종으로 예측한 클래스 값과 실제 레이블이 의미하는 클래스가 맞으면 correct에 더해 올바르게 예측한 횟수를 저장.  \n",
    "(12) 현재까지 계산된 'test_loss'의 값을 'test_loader'내에 존재하는 Mini-Batch 개수만큼 나눠 평균 Loss 값으로 계산.  \n",
    "(13) 'test_loader' 데이터 중 얼마나 맞췄는지를 계산해 정확도 계산.  \n",
    "(14) 계산된 'test_loss'값과 'test_accuracy'값을 반환.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa18b5d",
   "metadata": {},
   "source": [
    "### 10. MLP 학습을 실행하면서 Train, Test set의 Loss 및 Test set Accuracy 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f173c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Eppoch : 1 [0/60000(0%)]\tTrain Loss : 0.328932\n",
      "Train Eppoch : 1 [6400/60000(11%)]\tTrain Loss : 0.094827\n",
      "Train Eppoch : 1 [12800/60000(21%)]\tTrain Loss : 0.385518\n",
      "Train Eppoch : 1 [19200/60000(32%)]\tTrain Loss : 0.324488\n",
      "Train Eppoch : 1 [25600/60000(43%)]\tTrain Loss : 0.600698\n",
      "Train Eppoch : 1 [32000/60000(53%)]\tTrain Loss : 0.161923\n",
      "Train Eppoch : 1 [38400/60000(64%)]\tTrain Loss : 0.155005\n",
      "Train Eppoch : 1 [44800/60000(75%)]\tTrain Loss : 0.267721\n",
      "Train Eppoch : 1 [51200/60000(85%)]\tTrain Loss : 0.184284\n",
      "Train Eppoch : 1 [57600/60000(96%)]\tTrain Loss : 0.569933\n",
      "\n",
      "[EPOCH : 1], \tTest Loss : 0.0081, \tTest Accuracy : 92.51 %\n",
      "\n",
      "Train Eppoch : 2 [0/60000(0%)]\tTrain Loss : 0.287935\n",
      "Train Eppoch : 2 [6400/60000(11%)]\tTrain Loss : 0.378338\n",
      "Train Eppoch : 2 [12800/60000(21%)]\tTrain Loss : 0.242003\n",
      "Train Eppoch : 2 [19200/60000(32%)]\tTrain Loss : 0.253831\n",
      "Train Eppoch : 2 [25600/60000(43%)]\tTrain Loss : 0.141082\n",
      "Train Eppoch : 2 [32000/60000(53%)]\tTrain Loss : 0.369488\n",
      "Train Eppoch : 2 [38400/60000(64%)]\tTrain Loss : 0.164686\n",
      "Train Eppoch : 2 [44800/60000(75%)]\tTrain Loss : 0.156968\n",
      "Train Eppoch : 2 [51200/60000(85%)]\tTrain Loss : 0.380238\n",
      "Train Eppoch : 2 [57600/60000(96%)]\tTrain Loss : 0.272451\n",
      "\n",
      "[EPOCH : 2], \tTest Loss : 0.0081, \tTest Accuracy : 92.57 %\n",
      "\n",
      "Train Eppoch : 3 [0/60000(0%)]\tTrain Loss : 0.523032\n",
      "Train Eppoch : 3 [6400/60000(11%)]\tTrain Loss : 0.366873\n",
      "Train Eppoch : 3 [12800/60000(21%)]\tTrain Loss : 0.173882\n",
      "Train Eppoch : 3 [19200/60000(32%)]\tTrain Loss : 0.160589\n",
      "Train Eppoch : 3 [25600/60000(43%)]\tTrain Loss : 0.201832\n",
      "Train Eppoch : 3 [32000/60000(53%)]\tTrain Loss : 0.230085\n",
      "Train Eppoch : 3 [38400/60000(64%)]\tTrain Loss : 0.331915\n",
      "Train Eppoch : 3 [44800/60000(75%)]\tTrain Loss : 0.342995\n",
      "Train Eppoch : 3 [51200/60000(85%)]\tTrain Loss : 0.241375\n",
      "Train Eppoch : 3 [57600/60000(96%)]\tTrain Loss : 0.594350\n",
      "\n",
      "[EPOCH : 3], \tTest Loss : 0.0079, \tTest Accuracy : 92.69 %\n",
      "\n",
      "Train Eppoch : 4 [0/60000(0%)]\tTrain Loss : 0.231137\n",
      "Train Eppoch : 4 [6400/60000(11%)]\tTrain Loss : 0.328260\n",
      "Train Eppoch : 4 [12800/60000(21%)]\tTrain Loss : 0.418764\n",
      "Train Eppoch : 4 [19200/60000(32%)]\tTrain Loss : 0.637813\n",
      "Train Eppoch : 4 [25600/60000(43%)]\tTrain Loss : 0.450377\n",
      "Train Eppoch : 4 [32000/60000(53%)]\tTrain Loss : 0.251601\n",
      "Train Eppoch : 4 [38400/60000(64%)]\tTrain Loss : 0.163971\n",
      "Train Eppoch : 4 [44800/60000(75%)]\tTrain Loss : 0.195629\n",
      "Train Eppoch : 4 [51200/60000(85%)]\tTrain Loss : 0.313726\n",
      "Train Eppoch : 4 [57600/60000(96%)]\tTrain Loss : 0.330003\n",
      "\n",
      "[EPOCH : 4], \tTest Loss : 0.0079, \tTest Accuracy : 92.77 %\n",
      "\n",
      "Train Eppoch : 5 [0/60000(0%)]\tTrain Loss : 0.086508\n",
      "Train Eppoch : 5 [6400/60000(11%)]\tTrain Loss : 0.208466\n",
      "Train Eppoch : 5 [12800/60000(21%)]\tTrain Loss : 0.419392\n",
      "Train Eppoch : 5 [19200/60000(32%)]\tTrain Loss : 0.373736\n",
      "Train Eppoch : 5 [25600/60000(43%)]\tTrain Loss : 0.188152\n",
      "Train Eppoch : 5 [32000/60000(53%)]\tTrain Loss : 0.040074\n",
      "Train Eppoch : 5 [38400/60000(64%)]\tTrain Loss : 0.134346\n",
      "Train Eppoch : 5 [44800/60000(75%)]\tTrain Loss : 0.096864\n",
      "Train Eppoch : 5 [51200/60000(85%)]\tTrain Loss : 0.394920\n",
      "Train Eppoch : 5 [57600/60000(96%)]\tTrain Loss : 0.402830\n",
      "\n",
      "[EPOCH : 5], \tTest Loss : 0.0076, \tTest Accuracy : 93.05 %\n",
      "\n",
      "Train Eppoch : 6 [0/60000(0%)]\tTrain Loss : 0.454075\n",
      "Train Eppoch : 6 [6400/60000(11%)]\tTrain Loss : 0.350813\n",
      "Train Eppoch : 6 [12800/60000(21%)]\tTrain Loss : 0.150923\n",
      "Train Eppoch : 6 [19200/60000(32%)]\tTrain Loss : 0.092625\n",
      "Train Eppoch : 6 [25600/60000(43%)]\tTrain Loss : 0.207893\n",
      "Train Eppoch : 6 [32000/60000(53%)]\tTrain Loss : 0.287287\n",
      "Train Eppoch : 6 [38400/60000(64%)]\tTrain Loss : 0.114937\n",
      "Train Eppoch : 6 [44800/60000(75%)]\tTrain Loss : 0.342888\n",
      "Train Eppoch : 6 [51200/60000(85%)]\tTrain Loss : 0.301372\n",
      "Train Eppoch : 6 [57600/60000(96%)]\tTrain Loss : 0.288230\n",
      "\n",
      "[EPOCH : 6], \tTest Loss : 0.0075, \tTest Accuracy : 93.02 %\n",
      "\n",
      "Train Eppoch : 7 [0/60000(0%)]\tTrain Loss : 0.220619\n",
      "Train Eppoch : 7 [6400/60000(11%)]\tTrain Loss : 0.162668\n",
      "Train Eppoch : 7 [12800/60000(21%)]\tTrain Loss : 0.162055\n",
      "Train Eppoch : 7 [19200/60000(32%)]\tTrain Loss : 0.280854\n",
      "Train Eppoch : 7 [25600/60000(43%)]\tTrain Loss : 0.131997\n",
      "Train Eppoch : 7 [32000/60000(53%)]\tTrain Loss : 0.310253\n",
      "Train Eppoch : 7 [38400/60000(64%)]\tTrain Loss : 0.084589\n",
      "Train Eppoch : 7 [44800/60000(75%)]\tTrain Loss : 0.123527\n",
      "Train Eppoch : 7 [51200/60000(85%)]\tTrain Loss : 0.218202\n",
      "Train Eppoch : 7 [57600/60000(96%)]\tTrain Loss : 0.243731\n",
      "\n",
      "[EPOCH : 7], \tTest Loss : 0.0074, \tTest Accuracy : 93.22 %\n",
      "\n",
      "Train Eppoch : 8 [0/60000(0%)]\tTrain Loss : 0.327328\n",
      "Train Eppoch : 8 [6400/60000(11%)]\tTrain Loss : 0.083464\n",
      "Train Eppoch : 8 [12800/60000(21%)]\tTrain Loss : 0.061454\n",
      "Train Eppoch : 8 [19200/60000(32%)]\tTrain Loss : 0.426399\n",
      "Train Eppoch : 8 [25600/60000(43%)]\tTrain Loss : 0.052116\n",
      "Train Eppoch : 8 [32000/60000(53%)]\tTrain Loss : 0.222422\n",
      "Train Eppoch : 8 [38400/60000(64%)]\tTrain Loss : 0.048962\n",
      "Train Eppoch : 8 [44800/60000(75%)]\tTrain Loss : 0.275454\n",
      "Train Eppoch : 8 [51200/60000(85%)]\tTrain Loss : 0.232418\n",
      "Train Eppoch : 8 [57600/60000(96%)]\tTrain Loss : 0.085005\n",
      "\n",
      "[EPOCH : 8], \tTest Loss : 0.0072, \tTest Accuracy : 93.30 %\n",
      "\n",
      "Train Eppoch : 9 [0/60000(0%)]\tTrain Loss : 0.090942\n",
      "Train Eppoch : 9 [6400/60000(11%)]\tTrain Loss : 0.235033\n",
      "Train Eppoch : 9 [12800/60000(21%)]\tTrain Loss : 0.029487\n",
      "Train Eppoch : 9 [19200/60000(32%)]\tTrain Loss : 0.129590\n",
      "Train Eppoch : 9 [25600/60000(43%)]\tTrain Loss : 0.261743\n",
      "Train Eppoch : 9 [32000/60000(53%)]\tTrain Loss : 0.095691\n",
      "Train Eppoch : 9 [38400/60000(64%)]\tTrain Loss : 0.128145\n",
      "Train Eppoch : 9 [44800/60000(75%)]\tTrain Loss : 0.393132\n",
      "Train Eppoch : 9 [51200/60000(85%)]\tTrain Loss : 0.140571\n",
      "Train Eppoch : 9 [57600/60000(96%)]\tTrain Loss : 0.461260\n",
      "\n",
      "[EPOCH : 9], \tTest Loss : 0.0071, \tTest Accuracy : 93.25 %\n",
      "\n",
      "Train Eppoch : 10 [0/60000(0%)]\tTrain Loss : 0.280830\n",
      "Train Eppoch : 10 [6400/60000(11%)]\tTrain Loss : 0.126075\n",
      "Train Eppoch : 10 [12800/60000(21%)]\tTrain Loss : 0.135900\n",
      "Train Eppoch : 10 [19200/60000(32%)]\tTrain Loss : 0.189618\n",
      "Train Eppoch : 10 [25600/60000(43%)]\tTrain Loss : 0.303516\n",
      "Train Eppoch : 10 [32000/60000(53%)]\tTrain Loss : 0.248853\n",
      "Train Eppoch : 10 [38400/60000(64%)]\tTrain Loss : 0.222102\n",
      "Train Eppoch : 10 [44800/60000(75%)]\tTrain Loss : 0.389014\n",
      "Train Eppoch : 10 [51200/60000(85%)]\tTrain Loss : 0.428088\n",
      "Train Eppoch : 10 [57600/60000(96%)]\tTrain Loss : 0.220130\n",
      "\n",
      "[EPOCH : 10], \tTest Loss : 0.0070, \tTest Accuracy : 93.36 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for Epoch in range(1, EPOCHS + 1) :\n",
    "    train(model, train_loader, optimizer ,log_interval = 200)    # (1)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)      # (2)\n",
    "    print(\"\\n[EPOCH : {}], \\tTest Loss : {:.4f}, \\tTest Accuracy : {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25389ab",
   "metadata": {},
   "source": [
    "(1) 정의한 train 함수를 실행. model은 기존에 정의한 MLP 모델, train_loader는 학습 데이터, optimizer는 SGD, log_interval은 학습이 진행되면서 Mini-Batch의 Index를 이용해 과정을 모니터링할 수 있도록 출력하는 것을 의미.  \n",
    "(2) 각 Epoch 별로 출력되는 Loss 값과 accuracy 값 계산. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
